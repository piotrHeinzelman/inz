"Sztuczna inteligencja" zyskała w ostatnim czasie ogromną popularność. Wielkie firmy technologiczne udostępniły użytkownikom możliwość komunikacji ze swoimi wielkimi modelami językowymi LLM. Powstały modele językowe pracujące w języku polskim, m.in "Bielik", na dziś dostępna jest wersja BIELIK-11B-v2 mająca 11 000 000 parametrów. Uczenie tak dużych modeli szybciej niż konkurencja wymaga posiadania wielkich centrów obliczeniowych. 


W cieniu modeli językowych pozostają inne, dużo mniej medialne rozwiązania wykorzystywane od dziesięcioleci w przemyśle modele sieci MLP \cite{Korbicz1994}, \cite{Osowski2023}, \cite{Osowski2020}. Dziedzina "widzenia komputerowego" dostarcza modeli sieci głębokich CNN używanych w rozpoznawaniu obrazów, ich klasyfikacji a także  orientacji w przestrzeni. Modele te są używane zwłaszcza w robotyce. \cite{rasheed},
\cite{conv},
\cite{conv1}.

Sieć YOLO (ang. You Only Look Once), wykonująca jednocześnie funkcje klasyfikatora i systemu regresyjnego, który służy do wykrywania określonych obiektów w obrazie i określaniu ich współrzędnych. Sieć Yolo można pobrać w wersji wstępnie nauczonej i tylko douczyć do własnych zastosowań. Obecnie dostępna jest już 12 wersja\cite{ultralytics_doc}. 


Przygotowanie odpowiedzi przez model wymaga niewiele zasobów, a nauczony model można uruchamiać na tanim sprzęcie o małych możliwościach obliczeniowych. Jednak uczenie maszynowe wymaga wykorzystania dużej liczby próbek uczących w jednej epoce, a cały proces uczenia składa się z wielu powtórzeń. Proces uczenia wymaga albo dużych możliwości obliczeniowych albo dużej ilości czasu. Dokładne zestawienia zostaną opisane w kolejnych rozdziałach niniejszej pracy. 

Biblioteki dostarczające implementacje modeli sieci neuronowych powstały dla większości języków programowania ogólnego przeznaczenia. Niektóre z nich wykorzystują procesory graficzne do wysokowydajnych równoległych obliczeń, co powoduje wzrost wydajności i znaczące obniżenie czasu uczenia sieci. Budowanie własnych modeli sieci jest dziś w zasięgu osób prywatnych, hobbystów, studentów czy małych zespołów badawczych i nie wymaga ogromnych nakładów finansowych.

\section{ Cel pracy }
Podstawowym celem pracy jest ułatwienie podjęcia decyzji o wyborze języka i środowiska w fazie projektowej dla realizacji aplikacji wykorzystujących głębokie sieci neuronowe CNN. 

Celem dydaktycznym jest dogłębne zapoznanie się z tematyką sieci MLP \cite{Korbicz1994} oraz CNN \cite{MMuraszkiewiczRobertNowak} \cite{russell2023} poprzez realizacje i testy własnego rozwiązania zwłaszcza z wykorzystaniem możliwości obliczeniowych karty graficznej. 

\section{ Układ pracy }
W pierwszej części opisano proces przygotowania i uruchamiania sieci Yolo w różnych środowiskach, opisano aspekty takie jak wygoda tworzenia rozwiązania, dostęp do dokumentacji, ilość dostępnych przykładów.

W części drugiej przedstawiono skrótowo stan wiedzy z zakresu działania sieci neuronowych neuronowych tj. Perceptronu wielowarstwowego (ang. Multilayer Perceptron, MLP) oraz głębokich sieci neuronowych (ang. Convolutional Neural Network, CNN). 
Zaprezentowano na rysunkach propagację sygnałów przez sieć, propagację wsteczną i oparty na niej proces uczenia sieci.



W części trzeciej oszacowano ilości operacji niezbędnych dla obliczenia odpowiedzi sieci, oraz ilość operacji niezbędnych dla przeprowadzenia procesu uczenia. 

W części czwartej zaprezentowano sposoby wydajnej realizacji obliczeń :
Warunkiem niezbędnym do prowadzenia efektywnych badań nad głębokimi sieciami i dużymi modelami jest zdolność efektywnego wykorzystania systemów o dużych mocach obliczeniowych. W pierwszej części opisano metody zwiększania wydajności systemów cyfrowych i zagadnienia przetwarzania równoległego.



W piątej części zaprezentowano zadania, które będą rozwiązywane przez badane modele sieci.

W szóstej części zaprezentowano, wyniki pomiarów, dokonano podsumowania porównania wykonanych zadań w językach. 

Ostatnia część zawiera wyniki oraz przesłanki, które mogą być pomocne przy doborze języka w celu realizacji głębokich sieci neuronowych w zależności od konkretnych wymagań i możliwości stawianych projektowanym rozwiązaniom.

\section{ Kod źródłowy i dane uczące }
Przykłady rozwiązań w Python i Matlab zaczerpnięto 
\begin{itemize}
    \item z książek: 
        \cite{Osowski2023} 
        \cite{Osowski2020} 
        \cite{guido2021} 
        \cite{raschka2021}
    \item instrukcji i~przykładów załączonych do bibliotek
    \item otwartych repozytoriów git 
        \cite{yolov8_ultralytics}
        \cite{yolov8python}
        \cite{yolov8c}
\end{itemize}           
Obrazy treningowe 
\begin{itemize}
    \item pisma odręcznego pochodzą z bazy MNIST (yann.lecun.com)
    \item zdjęcia twarzy z serwisów: google.com oraz filmweb.pl
\end{itemize}    
Pełen kod dostępny na github:
\begin{itemize}
    \item github.com/piotrHeinzelman/inz/tree/main/MixedProj
\end{itemize}    

%W analizie nie brano pod uwagę czasów czytania plików oraz przygotowania danych.


 

%%%

%1) Wstęp - wymóg wysokiej wydajności w modelowaniu dużych / głębokich sieci.

%2) Sposoby zwiększania wydajności obliczeniowej systemów cyfrowych MMX, AVX, AVX512, i droga do obliczeń równoległych GPU. 

%a) operacje równoległego wieloskładnikowego mnożenia
%b) operacje wielokanałowego dodawania - realizacja dodawania równoległego.

%3) Stan wiedzy - model matematyczny MLP
%a) realizacja modeli w systemach cyfrowych z wykorzystaniem równoległego mnożenia i wielokanałowego dodawania.

%4) Stan wiedzy - model matematyczny CNN 
%a) realizacja modelu z wykorzystaniem równoległego mnożenia i wielokanałowego dodawania.

%5) Wydajność
%a) teoretyczna wydajność modeli MLP i CNN
%b) rzeczywista wydajność modeli implementowanych w językach
%- zad1
%- zad2
%- zad3

%6) Pozostałe aspekty języków.
%- opis aspektów
%- opis języków
%- przykłady kodu

%7) Porównanie wyników badań i wnioski.

%%