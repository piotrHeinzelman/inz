% https://www.mathworks.com/help/vision/ref/trainyolov4objectdetector.html#d126e346295
% Subnetworks to freeze during training, specified as one of these values:
%    "none" — Do not freeze subnetworks
%    "backbone" — Freeze the feature extraction subnetwork
%    "backboneAndNeck" — Freeze both the feature extraction and the path aggregation subnetworks

% Number of filters in the output convolutional layer must be 18 for 3 anchor boxes and 1 classes.
% Number of filters in the output convolutional layer must be 21 for 3 anchor boxes and 2 classes.

epoch=10;
path="../../imagesAndRegions/sequence_1/";
load("toolsTrainingData.mat");
load("netCNN_SAS.mat");
%load("dlnet.mat");
%net=dlnet;
trainingData=toolsTrainingData;

%disp(net.Layers);

dataDir = fullfile(path );
trainingData.imageFilename = fullfile("",trainingData.imageFilename);


imds = imageDatastore(trainingData.imageFilename);
blds = boxLabelDatastore(trainingData(:,2:end));
ds = combine(imds,blds);

inputSize = [240 240 3];
trainingDataForEstimation = transform(ds,@(data)preprocessData(data,inputSize));

numAnchors = 6;
[anchors,meanIoU] = estimateAnchorBoxes( blds, numAnchors);
area = anchors(:,1).*anchors(:,2);
[~,idx] = sort(area,"descend");
anchors = anchors(idx,:);
anchorBoxes = {anchors(1:3,:);anchors(4:6,:)};
aboxes=anchorBoxes;

classes = ["sas" ]; 
anchorBoxes = {[122,177;223,84;80,94] };


%detector = yolov4ObjectDetector(net,classes,aboxes,'DetectionNetworkSource',layer );


 









%netUpdated = removeLayers( net , ['softmax'] );
%net2 = removeLayers( netUpdated , ['fc'] );
 

imageSize = net.Layers(1).InputSize;
layerName = net.Layers(1).Name;
newInputLayer = imageInputLayer(imageSize,Normalization="none",Name=layerName);
%Replace the image input layer in the base network with the new input layer.
dlnet = replaceLayer(net,layerName,newInputLayer);
%Specify the names of the feature extraction layers in the base network to use as the detection heads.
featureExtractionLayers = ["Lay" ]; % ["activation_22_relu","activation_40_relu"];


net=net.removeLayers("softmax");
net=net.removeLayers("fc");
%net=net.removeLayers("fc_2"); 

detector = yolov4ObjectDetector(net,classes,anchorBoxes );
  %  DetectionNetworkSource=featureExtractionLayers);



%disp(detector) ;
if (false) 
    analyzeNetwork(detector.Network); 
end




options = trainingOptions("sgdm", ...
    InitialLearnRate=0.01, ...
    MaxEpochs=epoch, ...
    Shuffle="every-epoch", ...ValidationData=imdsValidation, ...
    ValidationFrequency=30, ...
    Plots="training-progress", ...
    Metrics="accuracy", ...
    Verbose=false);




detector = trainYOLOv4ObjectDetector(trainingData,detector,options)
 

I = imread("dedra_www.jpg");
[bboxes, scores, labels] = detect(detector, I, Threshold=0.8);
objBoxes = bboxes(labels=="sas", :);
detectedImg = insertObjectAnnotation(I, "Rectangle", objBoxes, "sas");
figure
imshow(detectedImg)

 