10% data, 64 neurons, 10 * 1500 epochs, = 82,3 accuracy
20% data, 64 neurons, 10 * 1500 epochs, = 82,95 accuracy
50% data, 64 neurons, 10 * 1500 epochs, = 84,74 accuracy
100% data, 64 neurons, 10 * 1500 epochs, = 88,34 accuracy 
100% data, 32 neurons, 15 * 1500 epochs, = 87,6 accuracy  
100% data, 16 neurons, 15 * 1500 epochs, = 71,04 accuracy  
100% data, 12 neurons, 15 * 1500 epochs, = 77,93 accuracy  
100% data, 128 neurons, 10 * 1500 epochs, = 87,54 accuracy 

64 neurons, 5000 epochs:          net = feedforwardnet([ 64,64 ],'traingd');

TIME:

>> matlab
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.798700

m[]=2292.547034
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.803100

m[]=2305.270410
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.818700

m[]=2294.247355
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.814300

m[]=2278.552440
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.805300

m[]=2235.181496
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.824600

m[]=2224.170047
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.826700

m[]=2219.340938
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.794200

m[]=2200.751765
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.806500

m[]=2164.676469
# MLP: 2x64Neu * 5000cycles: (Win10, IDE Matlab)
# accuracy: a:0.818800

m[]=2192.483457
>> 






























Epoch	0	397	1000
Elapsed Time	-	00:00:01	-
Performance	3.58	0.0189	0
Gradient	18.5	0.0729	1e-05
Validation Checks	0	6	6

perf =

    0.5461


z =

    0.1252
    0.6905
    0.1925
    0.9182
    0.1350
    0.6169
    0.1286
    0.2669
    0.6311
    0.4637


z =

    0.0597
    0.0515
    0.0965
   -0.0561
    0.0136
    0.0481
    0.0172
   -0.1231
   -0.0606
    0.9910


z =

    0.0151
    0.0359
    0.0263
    0.9657
   -0.1141
    0.0339
    0.0326
   -0.0031
   -0.0762
   -0.0727








50% danych 
net = feedforwardnet([ 64,64 ],'traingd');


perf =

    0.0718


z =

    0.0817
    0.1304
    0.3120
    0.0828
    0.3791
   -0.0288
    0.1241
    0.0756
    0.0660
    0.2135


z =

    0.0628
   -0.2785
    0.0165
   -0.1149
   -0.0724
   -0.1892
    0.1551
   -0.2057
    0.1261
    0.5619


z =

    0.1992
    0.5189
    0.1358
    0.6456
    0.4415
   -0.2298
    0.0036
    0.0831
   -0.0146
    0.0374