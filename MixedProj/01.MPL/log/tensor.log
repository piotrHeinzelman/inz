----------- WINDOWS ----------------
GPU
/device:GPU:0

  1/313 [..............................] - ETA: 34s - loss: 0.5633 - accuracy: 0.8438
 30/313 [=>............................] - ETA: 0s - loss: 0.7003 - accuracy: 0.7802 
 61/313 [====>.........................] - ETA: 0s - loss: 0.7504 - accuracy: 0.7623
 92/313 [=======>......................] - ETA: 0s - loss: 0.7574 - accuracy: 0.7585
123/313 [==========>...................] - ETA: 0s - loss: 0.7550 - accuracy: 0.7564
154/313 [=============>................] - ETA: 0s - loss: 0.7511 - accuracy: 0.7585
184/313 [================>.............] - ETA: 0s - loss: 0.7129 - accuracy: 0.7728
214/313 [===================>..........] - ETA: 0s - loss: 0.7001 - accuracy: 0.7791
245/313 [======================>.......] - ETA: 0s - loss: 0.6727 - accuracy: 0.7889
275/313 [=========================>....] - ETA: 0s - loss: 0.6566 - accuracy: 0.7922
306/313 [============================>.] - ETA: 0s - loss: 0.6440 - accuracy: 0.7991
313/313 [==============================] - 1s 2ms/step - loss: 0.6474 - accuracy: 0.7989
# Python, MLP: 2x 64 Neu, data size= 60000 
# train: epochs= 5 , time= 19.641895055770874 [s], one epoch time= 3.928379011154175 [s], one forward&backward time= 0.06547298351923625 [ms]
# accuracy= 0.7989000082015991 , forward one epoch time= 0.7969269752502441 [s], one propagation time= 0.07969269752502442 [ms]

--------------------------------------



  1/313 [..............................] - ETA: 21s - loss: 0.6112 - accuracy: 0.8438108/313 [=========>....................] - ETA: 0s - loss: 0.7933 - accuracy: 0.7381 217/313 [===================>..........] - ETA: 0s - loss: 0.7492 - accuracy: 0.7540313/313 [==============================] - 0s 463us/step - loss: 0.7004 - accuracy: 0.7718
# Python, MLP: 2x 64 Neu, data size= 60000 
# train: epochs= 5 , time= 5.949586391448975 [s], one epoch time= 1.1899172782897949 [s], one forward&backward time= 0.01983195463816325 [ms]
# accuracy= 0.7717999815940857 , forward one epoch time= 0.24862051010131836 [s], one propagation time= 0.024862051010131836 [ms]

[1m  1/313[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m20s[0m 67ms/step - accuracy: 0.7500 - loss: 0.5687[1m 92/313[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 553us/step - accuracy: 0.7780 - loss: 0.6837[1m189/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 534us/step - accuracy: 0.7744 - loss: 0.6940[1m288/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 526us/step - accuracy: 0.7819 - loss: 0.6774[1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 554us/step - accuracy: 0.7842 - loss: 0.6719
# Python, MLP: 2x 64 Neu, data size= 60000 
# train: epochs= 5 , time= 7.180604934692383 [s], one epoch time= 1.4361209869384766 [s], one forward&backward time= 0.023935349782307942 [ms]
# accuracy= 0.8086000084877014 , forward one epoch time= 0.2811894416809082 [s], one propagation time= 0.02811894416809082 [ms]

[1m  1/313[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m20s[0m 66ms/step - accuracy: 0.8125 - loss: 0.5797[1m 93/313[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 546us/step - accuracy: 0.7663 - loss: 0.7386[1m190/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 531us/step - accuracy: 0.7592 - loss: 0.7499[1m287/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 527us/step - accuracy: 0.7644 - loss: 0.7318[1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 554us/step - accuracy: 0.7664 - loss: 0.7254
# Python, MLP: 2x 64 Neu, data size= 60000 
# train: epochs= 5 , time= 7.0186927318573 [s], one epoch time= 1.40373854637146 [s], one forward&backward time= 0.02339564243952433 [ms]
# accuracy= 0.7878000140190125 , forward one epoch time= 0.2821667194366455 [s], one propagation time= 0.02821667194366455 [ms]
